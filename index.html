<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>MIMO Companion</title>
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            margin: 0;
            padding: 0;
            background-color: #050505;
            font-family: 'JetBrains Mono', monospace;
            overflow: hidden;
            touch-action: none;
            color: #ffffff;
            height: 100dvh;
        }
        .scanline {
            width: 100%;
            height: 2px;
            background: rgba(34, 211, 238, 0.05);
            position: absolute;
            top: 0;
            left: 0;
            pointer-events: none;
            z-index: 5;
            animation: scan 6s linear infinite;
        }
        @keyframes scan {
            0% { transform: translateY(0); }
            100% { transform: translateY(100vh); }
        }
        .power-pulse {
            animation: pulse-cyan 2.5s infinite ease-in-out;
        }
        @keyframes pulse-cyan {
            0%, 100% { opacity: 0.4; transform: scaleX(0.95); }
            50% { opacity: 0.8; transform: scaleX(1); }
        }
        .speaking-glow {
            animation: glow-pulse 0.5s infinite alternate;
        }
        @keyframes glow-pulse {
            from { filter: drop-shadow(0 0 5px rgba(34, 211, 238, 0.5)); }
            to { filter: drop-shadow(0 0 20px rgba(34, 211, 238, 1)); }
        }
        .mic-active {
            animation: mic-pulse 1.5s infinite;
        }
        @keyframes mic-pulse {
            0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(34, 211, 238, 0.7); }
            70% { transform: scale(1.1); box-shadow: 0 0 0 15px rgba(34, 211, 238, 0); }
            100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(34, 211, 238, 0); }
        }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        const apiKey = ""; // Managed by environment

        const Icons = {
            Settings: () => (
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M12.22 2h-.44a2 2 0 0 0-2 2l-.2.1a2 2 0 0 1-2.81.35l-.17-.1a2 2 0 0 0-2.82.73l-.22.38a2 2 0 0 0 .73 2.82l.14.1a2 2 0 0 1 .35 2.82l-.1.14a2 2 0 0 0 .73 2.82l.38.22a2 2 0 0 0 2.82-.73l.1-.14a2 2 0 0 1 2.82-.35l.14.1a2 2 0 0 0 2.82-.73l.22-.38a2 2 0 0 0-.73-2.82l-.14-.1a2 2 0 0 1-.35-2.82l.1-.14a2 2 0 0 0-.73-2.82l-.38-.22a2 2 0 0 0-2.82.73l-.1.14a2 2 0 0 1-2.82.35l-.14-.1a2 2 0 0 0-2.82.73l-.22.38a2 2 0 0 0 .73 2.82l.14.1a2 2 0 0 1 .35 2.82l-.1.14a2 2 0 0 0 .73 2.82l.38.22a2 2 0 0 0 2.82-.73l.1-.14a2 2 0 0 1 2.82-.35l.14.1a2 2 0 0 0 2.82-.73l.22-.38a2 2 0 0 0-.73-2.82l-.14-.1a2 2 0 0 1-.35-2.82l.1-.14a2 2 0 0 0-.73-2.82z"/><circle cx="12" cy="12" r="3"/></svg>
            ),
            Rotate: () => (
                <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round" className="text-cyan-500 animate-[spin_4s_linear_infinite]"><path d="M21 12a9 9 0 1 1-9-9c2.52 0 4.93 1 6.74 2.74L21 8"/><path d="M21 3v5h-5"/></svg>
            ),
            Zap: () => (
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="text-cyan-400"><polygon points="13 2 3 14 12 14 11 22 21 10 12 10 13 2"/></svg>
            ),
            Mic: () => (
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" y1="19" x2="12" y2="22"/></svg>
            )
        };

        const App = () => {
            const [isLandscape, setIsLandscape] = useState(false);
            const [isAsleep, setIsAsleep] = useState(true);
            const [mood, setMood] = useState('neutral');
            const [eyePos, setEyePos] = useState({ x: 0, y: 0 });
            const [isBlinking, setIsBlinking] = useState(false);
            const [showSettings, setShowSettings] = useState(false);
            const [isListening, setIsListening] = useState(false);
            const [isProcessing, setIsProcessing] = useState(false);
            const [isSpeaking, setIsSpeaking] = useState(false);
            const [localKey, setLocalKey] = useState(localStorage.getItem('mimo_key') || "");

            const recognitionRef = useRef(null);

            useEffect(() => {
                const checkOrientation = () => {
                    setIsLandscape(window.innerWidth > window.innerHeight);
                };
                window.addEventListener('resize', checkOrientation);
                checkOrientation();
                return () => window.removeEventListener('resize', checkOrientation);
            }, []);

            // Speech Recognition Setup
            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (SpeechRecognition && isLandscape && !isAsleep) {
                    recognitionRef.current = new SpeechRecognition();
                    recognitionRef.current.continuous = true;
                    recognitionRef.current.interimResults = true;
                    recognitionRef.current.lang = 'en-US';

                    recognitionRef.current.onresult = (event) => {
                        const transcript = Array.from(event.results)
                            .map(result => result[0])
                            .map(result => result.transcript)
                            .join('')
                            .toLowerCase();

                        // Detect Wakeword
                        if (transcript.includes("hey mimo") || transcript.includes("hey memo") || transcript.includes("hey meemo")) {
                            if (!isListening && !isProcessing && !isSpeaking) {
                                triggerVoicePrompt();
                            }
                        }
                    };

                    recognitionRef.current.onend = () => {
                        // Keep listening for wakeword if awake
                        if (!isAsleep) recognitionRef.current.start();
                    };

                    recognitionRef.current.start();
                }

                return () => {
                    if (recognitionRef.current) recognitionRef.current.stop();
                };
            }, [isLandscape, isAsleep]);

            const triggerVoicePrompt = () => {
                setIsListening(true);
                setMood('neutral');
                // Give user feedback they can speak now
                setTimeout(() => {
                    // Logic to capture the actual command starts here
                    // For this simplified version, we'll stop the wakeword listener
                    // and start a fresh single-shot recognition for the command
                    if (recognitionRef.current) recognitionRef.current.stop();
                    
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    const commandRec = new SpeechRecognition();
                    commandRec.lang = 'en-US';
                    
                    commandRec.onresult = (event) => {
                        const command = event.results[0][0].transcript;
                        handleConversation(command);
                    };
                    
                    commandRec.onend = () => {
                        setIsListening(false);
                        if (recognitionRef.current && !isAsleep) recognitionRef.current.start();
                    };

                    commandRec.start();
                }, 500);
            };

            // Idle behaviors
            useEffect(() => {
                if (!isLandscape || isAsleep || isSpeaking) return;
                const moveInterval = setInterval(() => {
                    if (mood === 'neutral') {
                        setEyePos({ x: (Math.random() - 0.5) * 40, y: (Math.random() - 0.5) * 20 });
                    }
                }, 4000);
                const blinkInterval = setInterval(() => {
                    setIsBlinking(true);
                    setTimeout(() => setIsBlinking(false), 120);
                }, 5000 + Math.random() * 4000);
                return () => { clearInterval(moveInterval); clearInterval(blinkInterval); };
            }, [isLandscape, isAsleep, isSpeaking, mood]);

            const pcmToWav = (pcmData, sampleRate) => {
                const buffer = new ArrayBuffer(44 + pcmData.length * 2);
                const view = new DataView(buffer);
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) view.setUint8(offset + i, string.charCodeAt(i));
                };
                writeString(0, 'RIFF');
                view.setUint32(4, 32 + pcmData.length * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, pcmData.length * 2, true);
                for (let i = 0, offset = 44; i < pcmData.length; i++, offset += 2) view.setInt16(offset, pcmData[i], true);
                return buffer;
            };

            const apiCall = async (url, body, retries = 5) => {
                const key = localKey || apiKey;
                for (let i = 0; i < retries; i++) {
                    try {
                        const response = await fetch(`${url}&key=${key}`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(body)
                        });
                        if (!response.ok) throw new Error(`HTTP ${response.status}`);
                        return await response.json();
                    } catch (e) {
                        if (i === retries - 1) throw e;
                        await new Promise(r => setTimeout(r, Math.pow(2, i) * 1000));
                    }
                }
            };

            const speak = async (text) => {
                try {
                    setIsSpeaking(true);
                    const result = await apiCall(
                        'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?',
                        {
                            contents: [{ parts: [{ text: `Say in a cute, helpful robotic voice: ${text}` }] }],
                            generationConfig: {
                                responseModalities: ["AUDIO"],
                                speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Kore" } } }
                            }
                        }
                    );
                    const audioData = result.candidates[0].content.parts[0].inlineData;
                    const pcmData = new Int16Array(Uint8Array.from(atob(audioData.data), c => c.charCodeAt(0)).buffer);
                    const wavBuffer = pcmToWav(pcmData, 24000);
                    const blob = new Blob([wavBuffer], { type: 'audio/wav' });
                    const audio = new Audio(URL.createObjectURL(blob));
                    audio.onended = () => { setIsSpeaking(false); setMood('neutral'); };
                    audio.play();
                } catch (e) { console.error("TTS Error", e); setIsSpeaking(false); }
            };

            const handleConversation = async (userQuery) => {
                if (isProcessing) return;
                setIsProcessing(true);
                try {
                    const result = await apiCall(
                        'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?',
                        {
                            contents: [{ parts: [{ text: userQuery }] }],
                            systemInstruction: { parts: [{ text: "You are MIMO, a professional but cute robot companion. Keep responses brief (under 15 words). Friendly but efficient." }] }
                        }
                    );
                    const text = result.candidates?.[0]?.content?.parts?.[0]?.text;
                    if (text) { setMood('happy'); await speak(text); }
                } catch (e) { console.error("Chat Error", e); } finally { setIsProcessing(false); }
            };

            if (!isLandscape) {
                return (
                    <div className="flex flex-col items-center justify-center min-h-[100dvh] p-6 text-center bg-[#050505]">
                        <div className="relative mb-12"><div className="w-24 h-44 border-2 border-zinc-800 rounded-[2.5rem] flex items-center justify-center"><Icons.Rotate /></div></div>
                        <h1 className="text-2xl font-bold tracking-[0.2em] uppercase mb-4">Initialize MIMO</h1>
                        <p className="text-zinc-500 max-w-xs text-xs tracking-widest leading-relaxed">Rotate device to landscape orientation.</p>
                    </div>
                );
            }

            return (
                <div className="relative w-full h-[100dvh] flex items-center justify-center overflow-hidden bg-black">
                    <div className="scanline" />
                    
                    <button onClick={() => setShowSettings(true)} className="absolute top-6 right-6 p-2 text-zinc-600 hover:text-cyan-400 z-50 transition-colors">
                        <Icons.Settings />
                    </button>

                    {/* Microphone Listener UI */}
                    {isListening && (
                        <div className="absolute bottom-8 left-8 z-50">
                            <div className="bg-cyan-500 p-4 rounded-full mic-active text-black">
                                <Icons.Mic />
                            </div>
                        </div>
                    )}

                    <div className="absolute top-8 left-8 flex flex-col gap-1 z-10">
                        <div className="text-[10px] text-cyan-500 font-bold tracking-[0.3em] uppercase">MIMO-OS_v2.5</div>
                        <div className="flex items-center gap-2 text-[8px] text-zinc-500 font-mono tracking-tighter uppercase">
                            <div className={`w-1.5 h-1.5 rounded-full ${isAsleep ? 'bg-cyan-900' : 'bg-cyan-500 animate-pulse'}`} />
                            {isAsleep ? 'Standby' : isListening ? 'Listening...' : 'Neural Link Active'}
                        </div>
                    </div>

                    <div className="w-full h-full flex items-center justify-center" onClick={() => { if(isAsleep) setIsAsleep(false); }}>
                        <div 
                            className={`flex gap-24 md:gap-48 items-center justify-center transition-all duration-1000 ease-out ${isAsleep ? 'opacity-60' : 'opacity-100'}`}
                            style={{ transform: `translate(${eyePos.x}px, ${eyePos.y}px)` }}
                        >
                            <Eye isBlinking={isBlinking} mood={mood} isAsleep={isAsleep} isSpeaking={isSpeaking} />
                            <Eye isBlinking={isBlinking} mood={mood} isAsleep={isAsleep} isSpeaking={isSpeaking} />
                        </div>
                    </div>

                    <div className="absolute top-12 left-1/2 -translate-x-1/2 flex flex-col items-center">
                        {isAsleep ? (
                            <div className="px-6 py-1 border border-cyan-500/10 bg-cyan-500/5 rounded-full text-[8px] text-cyan-600 uppercase tracking-[0.4em] power-pulse">
                                Tap Interface to Wake
                            </div>
                        ) : !isListening && (
                            <div className="px-6 py-1 border border-zinc-900 bg-zinc-900/10 rounded-full text-[8px] text-zinc-600 uppercase tracking-[0.4em]">
                                Say "Hey Mimo"
                            </div>
                        )}
                    </div>

                    {showSettings && (
                        <div className="absolute inset-0 bg-black/95 backdrop-blur-xl z-[100] flex items-center justify-center p-6">
                            <div className="w-full max-w-sm border border-zinc-800 bg-zinc-950 p-8 rounded-3xl">
                                <h2 className="text-sm font-bold tracking-widest text-cyan-500 uppercase mb-6">Neural Link Config</h2>
                                <input 
                                    type="password"
                                    value={localKey}
                                    onChange={(e) => { setLocalKey(e.target.value); localStorage.setItem('mimo_key', e.target.value); }}
                                    placeholder="Gemini API Key..."
                                    className="w-full bg-zinc-900 border border-zinc-800 rounded-xl px-4 py-3 text-xs text-white focus:border-cyan-500 outline-none mb-4"
                                />
                                <button onClick={() => setShowSettings(false)} className="w-full bg-cyan-600 hover:bg-cyan-500 text-white py-3 rounded-xl text-[10px] font-bold uppercase tracking-widest transition-all">
                                    Save Config
                                </button>
                            </div>
                        </div>
                    )}
                </div>
            );
        };

        const Eye = ({ isBlinking, mood, isAsleep, isSpeaking }) => {
            return (
                <div className={`w-40 h-40 md:w-56 md:h-56 bg-zinc-900/40 rounded-[40px] md:rounded-[50px] p-8 flex items-center justify-center border border-zinc-800/30 ${isBlinking ? 'scale-y-0 opacity-0' : 'scale-y-100 opacity-100'} transition-all duration-[120ms] ${isSpeaking ? 'speaking-glow' : ''}`}>
                    <div className="w-full h-full flex items-center justify-center">
                        {isAsleep ? (
                            <div className="w-full h-2 bg-cyan-500/80 rounded-full shadow-[0_0_15px_rgba(6,182,212,0.6)] power-pulse" />
                        ) : mood === 'happy' ? (
                            <svg viewBox="0 0 100 100" className="w-full h-full fill-cyan-400 drop-shadow-[0_0_15px_rgba(34,211,238,0.8)]"><path d="M10,65 C20,30 80,30 90,65 L90,80 C80,45 20,45 10,80 Z" /></svg>
                        ) : (
                            <div className={`w-full h-full bg-cyan-400 rounded-[20px] md:rounded-[28px] shadow-[0_0_25px_rgba(6,182,212,0.5)] ${isSpeaking ? 'animate-pulse' : ''}`} />
                        )}
                    </div>
                </div>
            );
        };

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>

